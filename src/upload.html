<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Upload - Audio Transcription</title>
    <link rel="stylesheet" href="styles.css" />
  </head>
  <body>
    <div class="container">
      <h1>Audio Transcription</h1>
      <p class="subtitle">Upload a file or record audio directly.</p>

      <!-- Tab Switcher -->
      <div class="tab-switcher">
        <button class="tab-btn active" id="upload-tab" data-mode="upload">
          Upload File
        </button>
        <button class="tab-btn" id="record-tab" data-mode="record">
          Record Audio
        </button>
      </div>

      <div class="error-message" id="error-message"></div>

      <!-- Progress Bar -->
      <div class="progress-container" id="progress-container">
        <div class="progress-bar">
          <div class="progress-fill"></div>
        </div>
        <div class="progress-text">Transcribing your audio... This may take a moment.</div>
      </div>

      <!-- Upload Mode -->
      <div id="upload-mode" class="mode-container">
        <div class="drop-zone" id="drop-zone">
          <div class="drop-text">Drop audio file here or click to browse</div>
          <div class="drop-subtext">Supports MP3, WAV, M4A, WEBM, MP4 â€¢ Large files supported</div>
          <input
            type="file"
            id="file-input"
            accept=".mp3,.wav,.m4a,.webm,.mp4,.mpeg,.mpga"
            style="display: none"
          />
        </div>

        <div class="file-info" id="file-info">
          <div class="file-name" id="file-name"></div>
          <div class="file-size" id="file-size"></div>
        </div>
      </div>

      <!-- Record Mode -->
      <div id="record-mode" class="mode-container" style="display: none">
        <div class="record-container">
          <div class="record-visualizer" id="record-visualizer">
            <div class="record-status" id="record-status">Ready to record</div>
            <div class="record-timer" id="record-timer">00:00</div>
          </div>

          <div class="record-controls">
            <button class="record-btn" id="start-record-btn">
              <span class="record-dot"></span>
              Record
            </button>
            <button class="record-btn secondary" id="stop-record-btn" style="display: none">
              <span class="stop-icon"></span>
              Stop
            </button>
          </div>
        </div>

        <div class="file-info" id="recording-info" style="display: none">
          <div class="file-name" id="recording-name">Recording.webm</div>
          <div class="file-size" id="recording-size"></div>
        </div>
      </div>

      <!-- Model Selection Section -->
      <div class="model-section" id="model-section" style="display: none">
        <div class="model-options">
          <label class="model-option">
            <input type="radio" name="model" value="gpt-4o-transcribe" checked />
            <div class="model-option-content">
              <div class="model-option-title">Standard Transcription</div>
              <div class="model-option-description">High-quality text transcription with timestamps</div>
            </div>
          </label>
          <label class="model-option">
            <input type="radio" name="model" value="gpt-4o-transcribe-diarize" />
            <div class="model-option-content">
              <div class="model-option-title">Speaker Identification</div>
              <div class="model-option-description">Identifies who is speaking with labeled segments</div>
            </div>
          </label>
        </div>
      </div>

      <!-- Speaker References Section (only shown when diarize is selected) -->
      <div class="speaker-section" id="speaker-section" style="display: none">
        <div class="speaker-header" id="speaker-header">
          <div class="speaker-header-content">
            <span class="speaker-title">Known Speakers</span>
            <span class="speaker-subtitle">Optional - Upload 2-10 second clips</span>
          </div>
          <span class="speaker-chevron" id="speaker-chevron">â–¼</span>
        </div>
        <div class="speaker-body" id="speaker-body">
          <div class="speaker-list" id="speaker-list">
            <!-- Speaker reference items will be added here dynamically -->
          </div>
          <button class="btn-add-speaker" id="add-speaker-btn">+ Add Speaker</button>
          <div class="speaker-hint">Upload short audio clips (2-10 seconds) to identify specific speakers by name</div>
          <input type="file" id="speaker-input" accept=".mp3,.wav,.m4a,.webm,.mp4,.mpeg,.mpga" style="display: none" />
        </div>
      </div>

      <!-- Prompt Section -->
      <div class="prompt-section" id="prompt-section" style="display: none">
        <div class="prompt-header" id="prompt-header">
          <div class="prompt-header-content">
            <span class="prompt-title">Improve transcription</span>
            <span class="prompt-subtitle">Optional</span>
          </div>
          <span class="prompt-chevron" id="prompt-chevron">â–¼</span>
        </div>
        <div class="prompt-body" id="prompt-body">
          <div class="prompt-examples" id="prompt-examples">
            <div class="prompt-examples-title">Example prompts:</div>
            <div class="prompt-example" data-prompt="Names: Patrick Freyer, Sarah Johnson, Michael Chen&#10;Companies: Boston Consulting Group (BCG), Microsoft, OpenAI&#10;Topics: Digital transformation, AI strategy, cloud migration">
              <div class="prompt-example-label">Business Meeting</div>
              <div class="prompt-example-text">Names, companies, and meeting topics</div>
            </div>
            <div class="prompt-example" data-prompt="Technical terms: API, REST, GraphQL, microservices, Kubernetes, Docker&#10;Languages: Python, TypeScript, JavaScript&#10;Frameworks: React, Node.js, FastAPI">
              <div class="prompt-example-label">Technical Presentation</div>
              <div class="prompt-example-text">Programming terms and frameworks</div>
            </div>
            <div class="prompt-example" data-prompt="Medical terms: computed tomography (CT), magnetic resonance imaging (MRI)&#10;Medications: ibuprofen, acetaminophen, lisinopril&#10;Specialists: Dr. Smith, cardiologist, endocrinologist">
              <div class="prompt-example-label">Medical Discussion</div>
              <div class="prompt-example-text">Medical terminology and names</div>
            </div>
          </div>
          <textarea
            class="prompt-textarea"
            id="prompt-textarea"
            placeholder="Add names, technical terms, or context to help Whisper understand your audio better...&#10;&#10;Example:&#10;Names: Patrick Freyer, John Smith&#10;Terms: API, ML, transcription&#10;Context: Product strategy meeting"
          ></textarea>
          <div class="prompt-footer">
            <div class="prompt-hint">
              ðŸ’¡ <a class="prompt-examples-link" id="show-examples">Show examples</a>
            </div>
            <div class="prompt-counter" id="prompt-counter">0 / ~560 chars</div>
          </div>
        </div>
      </div>

      <button class="btn" id="transcribe-btn" style="display: none">
        Transcribe
      </button>
      <button class="btn btn-secondary" id="settings-btn">Change API Key</button>

      <footer class="attribution">
        Created by <a href="https://patrickfreyer.com" target="_blank">Patrick C. Freyer</a>
        <br>
        <a href="mailto:freyer.patrick@bcg.com">freyer.patrick@bcg.com</a>
      </footer>
    </div>

    <script>
      // UI Elements
      const uploadTab = document.getElementById('upload-tab');
      const recordTab = document.getElementById('record-tab');
      const uploadMode = document.getElementById('upload-mode');
      const recordMode = document.getElementById('record-mode');
      const dropZone = document.getElementById('drop-zone');
      const fileInput = document.getElementById('file-input');
      const fileInfo = document.getElementById('file-info');
      const fileName = document.getElementById('file-name');
      const fileSize = document.getElementById('file-size');
      const recordingInfo = document.getElementById('recording-info');
      const recordingName = document.getElementById('recording-name');
      const recordingSize = document.getElementById('recording-size');
      const startRecordBtn = document.getElementById('start-record-btn');
      const stopRecordBtn = document.getElementById('stop-record-btn');
      const recordStatus = document.getElementById('record-status');
      const recordTimer = document.getElementById('record-timer');
      const transcribeBtn = document.getElementById('transcribe-btn');
      const settingsBtn = document.getElementById('settings-btn');
      const errorMessage = document.getElementById('error-message');
      const progressContainer = document.getElementById('progress-container');
      const promptSection = document.getElementById('prompt-section');
      const promptHeader = document.getElementById('prompt-header');
      const promptBody = document.getElementById('prompt-body');
      const promptChevron = document.getElementById('prompt-chevron');
      const promptTextarea = document.getElementById('prompt-textarea');
      const promptCounter = document.getElementById('prompt-counter');
      const showExamplesLink = document.getElementById('show-examples');
      const promptExamples = document.getElementById('prompt-examples');
      const promptExampleElements = document.querySelectorAll('.prompt-example');
      const modelSection = document.getElementById('model-section');
      const modelRadios = document.querySelectorAll('input[name="model"]');
      const speakerSection = document.getElementById('speaker-section');
      const speakerHeader = document.getElementById('speaker-header');
      const speakerBody = document.getElementById('speaker-body');
      const speakerChevron = document.getElementById('speaker-chevron');
      const speakerList = document.getElementById('speaker-list');
      const addSpeakerBtn = document.getElementById('add-speaker-btn');
      const speakerInput = document.getElementById('speaker-input');

      let selectedFile = null;
      let isPromptExpanded = false;
      let isSpeakerExpanded = false;
      let mediaRecorder = null;
      let audioChunks = [];
      let recordingStartTime = null;
      let timerInterval = null;
      let currentMode = 'upload';
      let speakerReferences = []; // { name: string, file: File }
      let currentSpeakerIndex = null;

      // Tab Switching
      uploadTab.addEventListener('click', () => switchMode('upload'));
      recordTab.addEventListener('click', () => switchMode('record'));

      function switchMode(mode) {
        currentMode = mode;

        // Update tabs
        uploadTab.classList.toggle('active', mode === 'upload');
        recordTab.classList.toggle('active', mode === 'record');

        // Update containers
        uploadMode.style.display = mode === 'upload' ? 'block' : 'none';
        recordMode.style.display = mode === 'record' ? 'block' : 'none';

        // Reset state
        selectedFile = null;
        transcribeBtn.style.display = 'none';
        fileInfo.classList.remove('show');
        recordingInfo.style.display = 'none';
        errorMessage.classList.remove('show');
        promptSection.style.display = 'none';
        promptTextarea.value = '';
        updatePromptCounter();
      }

      // ==================== UPLOAD MODE ====================

      // Click to browse
      dropZone.addEventListener('click', () => {
        fileInput.click();
      });

      // File input change
      fileInput.addEventListener('change', (e) => {
        if (e.target.files.length > 0) {
          handleFile(e.target.files[0]);
        }
      });

      // Drag and drop events
      dropZone.addEventListener('dragover', (e) => {
        e.preventDefault();
        dropZone.classList.add('drag-over');
      });

      dropZone.addEventListener('dragleave', () => {
        dropZone.classList.remove('drag-over');
      });

      dropZone.addEventListener('drop', (e) => {
        e.preventDefault();
        dropZone.classList.remove('drag-over');

        if (e.dataTransfer.files.length > 0) {
          handleFile(e.dataTransfer.files[0]);
        }
      });

      function handleFile(file) {
        errorMessage.classList.remove('show');

        // Check file type
        const fileExtension = '.' + file.name.split('.').pop().toLowerCase();
        const acceptedExtensions = [
          '.mp3',
          '.wav',
          '.m4a',
          '.webm',
          '.mp4',
          '.mpeg',
          '.mpga',
        ];

        if (!acceptedExtensions.includes(fileExtension)) {
          errorMessage.textContent =
            'Unsupported file type. Please use MP3, WAV, M4A, WEBM, or MP4.';
          errorMessage.classList.add('show');
          return;
        }

        // Note: No file size limit check - large files are now supported via chunking
        selectedFile = file;

        // Display file info
        fileName.textContent = file.name;
        fileSize.textContent = formatFileSize(file.size);
        fileInfo.classList.add('show');
        promptSection.style.display = 'block';
        transcribeBtn.style.display = 'block';
      }

      // ==================== RECORD MODE ====================

      startRecordBtn.addEventListener('click', async () => {
        try {
          const stream = await navigator.mediaDevices.getUserMedia({ audio: true });

          mediaRecorder = new MediaRecorder(stream, { mimeType: 'audio/webm' });
          audioChunks = [];

          mediaRecorder.ondataavailable = (event) => {
            audioChunks.push(event.data);
          };

          mediaRecorder.onstop = async () => {
            const audioBlob = new Blob(audioChunks, { type: 'audio/webm' });

            // Stop all tracks
            stream.getTracks().forEach(track => track.stop());

            // Clear timer
            clearInterval(timerInterval);

            try {
              // Convert blob to array buffer and save to temp file
              const arrayBuffer = await audioBlob.arrayBuffer();
              const result = await window.electron.saveRecording(arrayBuffer);

              if (result.success) {
                // Store the temp file path as a File-like object
                selectedFile = {
                  path: result.filePath,
                  name: 'recording.webm',
                  size: audioBlob.size,
                };

                // Display recording info
                recordingSize.textContent = formatFileSize(audioBlob.size);
                recordingInfo.style.display = 'block';
                promptSection.style.display = 'block';
                transcribeBtn.style.display = 'block';

                // Reset UI
                recordStatus.textContent = 'Recording complete';
                startRecordBtn.style.display = 'block';
                stopRecordBtn.style.display = 'none';
              } else {
                throw new Error(result.error);
              }
            } catch (error) {
              errorMessage.textContent = 'Failed to save recording: ' + error.message;
              errorMessage.classList.add('show');
              recordStatus.textContent = 'Ready to record';
              startRecordBtn.style.display = 'block';
              stopRecordBtn.style.display = 'none';
            }
          };

          mediaRecorder.start();
          recordingStartTime = Date.now();

          // Update UI
          recordStatus.textContent = 'Recording...';
          startRecordBtn.style.display = 'none';
          stopRecordBtn.style.display = 'block';
          recordingInfo.style.display = 'none';
          transcribeBtn.style.display = 'none';

          // Start timer
          timerInterval = setInterval(updateTimer, 1000);

        } catch (error) {
          errorMessage.textContent = 'Microphone access denied. Please enable microphone permissions.';
          errorMessage.classList.add('show');
        }
      });

      stopRecordBtn.addEventListener('click', () => {
        if (mediaRecorder && mediaRecorder.state !== 'inactive') {
          mediaRecorder.stop();
        }
      });

      function updateTimer() {
        const elapsed = Math.floor((Date.now() - recordingStartTime) / 1000);
        const minutes = Math.floor(elapsed / 60).toString().padStart(2, '0');
        const seconds = (elapsed % 60).toString().padStart(2, '0');
        recordTimer.textContent = `${minutes}:${seconds}`;
      }

      // ==================== SHARED ====================

      function formatFileSize(bytes) {
        if (bytes < 1024) return bytes + ' B';
        if (bytes < 1024 * 1024) return (bytes / 1024).toFixed(2) + ' KB';
        return (bytes / (1024 * 1024)).toFixed(2) + ' MB';
      }

      // ==================== PROMPT SECTION ====================

      // Toggle prompt section
      promptHeader.addEventListener('click', () => {
        isPromptExpanded = !isPromptExpanded;
        promptBody.classList.toggle('expanded', isPromptExpanded);
        promptChevron.classList.toggle('expanded', isPromptExpanded);
      });

      // Update character counter
      function updatePromptCounter() {
        const length = promptTextarea.value.length;
        const maxChars = 560; // Approximate for 224 tokens
        const warningThreshold = 500;

        promptCounter.textContent = `${length} / ~${maxChars} chars`;

        promptCounter.classList.remove('warning', 'error');
        if (length > maxChars) {
          promptCounter.classList.add('error');
        } else if (length > warningThreshold) {
          promptCounter.classList.add('warning');
        }
      }

      promptTextarea.addEventListener('input', updatePromptCounter);

      // Show/hide examples
      showExamplesLink.addEventListener('click', (e) => {
        e.preventDefault();
        const isVisible = promptExamples.classList.contains('show');
        promptExamples.classList.toggle('show', !isVisible);
        showExamplesLink.textContent = isVisible ? 'Show examples' : 'Hide examples';
      });

      // Use example prompts
      promptExampleElements.forEach(example => {
        example.addEventListener('click', () => {
          const promptText = example.getAttribute('data-prompt').replace(/&#10;/g, '\n');
          promptTextarea.value = promptText;
          updatePromptCounter();
          promptExamples.classList.remove('show');
          showExamplesLink.textContent = 'Show examples';
        });
      });

      // Listen for progress updates
      const progressText = document.querySelector('.progress-text');
      window.electron.onTranscriptionProgress((data) => {
        if (data.status === 'converting') {
          progressText.textContent = data.message || 'Converting audio format...';
        } else if (data.status === 'splitting') {
          progressText.textContent = data.message || 'Splitting large audio file...';
        } else if (data.status === 'transcribing') {
          if (data.current && data.total) {
            progressText.textContent = `${data.message} (${data.current}/${data.total})`;
          } else {
            progressText.textContent = data.message || 'Transcribing...';
          }
        } else if (data.status === 'combining') {
          progressText.textContent = data.message || 'Combining transcripts...';
        }
      });

      // Transcribe button
      transcribeBtn.addEventListener('click', async () => {
        if (!selectedFile) return;

        errorMessage.classList.remove('show');
        progressContainer.classList.add('show');
        progressText.textContent = 'Transcribing your audio... This may take a moment.';
        transcribeBtn.disabled = true;
        transcribeBtn.textContent = 'Transcribing...';

        try {
          const apiKey = await window.electron.getApiKey();

          if (!apiKey) {
            throw new Error('API key not found. Please set up your API key first.');
          }

          const prompt = promptTextarea.value.trim() || null;

          const result = await window.electron.transcribeAudio(
            selectedFile.path,
            apiKey,
            prompt
          );

          if (result.success) {
            // Store transcript in localStorage and navigate to transcript screen
            localStorage.setItem('transcript', result.transcript);
            localStorage.setItem('fileName', selectedFile.name);
            if (result.chunked) {
              localStorage.setItem('transcriptInfo', `Processed in ${result.totalChunks} chunks`);
            }
            window.electron.navigate('transcript');
          } else {
            throw new Error(result.error);
          }
        } catch (error) {
          errorMessage.textContent = error.message || 'Transcription failed';
          errorMessage.classList.add('show');
          progressContainer.classList.remove('show');
          transcribeBtn.disabled = false;
          transcribeBtn.textContent = 'Transcribe';
        }
      });

      // Settings button
      settingsBtn.addEventListener('click', () => {
        window.electron.navigate('setup');
      });
    </script>
  </body>
</html>
